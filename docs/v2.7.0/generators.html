

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>4. Generators &mdash; pysdg 2.5.0rc2.post1.dev30 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=bc5a8690"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="author" title="About these documents" href="about.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="5. References" href="references.html" />
    <link rel="prev" title="3. Usage" href="usage.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            pysdg
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="about.html">1. About <cite>pysdg</cite></a></li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">2. Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage.html">3. Usage</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">4. Generators</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#replica-seq">4.1. “replica/seq”</a></li>
<li class="toctree-l2"><a class="reference internal" href="#synthcity-bayesian-network">4.2. “synthcity/bayesian_network”</a></li>
<li class="toctree-l2"><a class="reference internal" href="#synthcity-ctgan">4.3. “synthcity/ctgan”</a></li>
<li class="toctree-l2"><a class="reference internal" href="#synthcity-tvae">4.4. “synthcity/tvae”</a></li>
<li class="toctree-l2"><a class="reference internal" href="#synthcity-rtvae">4.5. “synthcity/rtvae”</a></li>
<li class="toctree-l2"><a class="reference internal" href="#synthcity-arf">4.6. “synthcity/arf”</a></li>
<li class="toctree-l2"><a class="reference internal" href="#synthcity-nflow">4.7. “synthcity/nflow”</a></li>
<li class="toctree-l2"><a class="reference internal" href="#yandex-tabddpm">4.8. “yandex/tabddpm”</a></li>
<li class="toctree-l2"><a class="reference internal" href="#amazon-tabsyn">4.9. “amazon/tabsyn”</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="references.html">5. References</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_ref.html">6. API reference</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Extras</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="changelog.html">Changelog</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">pysdg</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active"><span class="section-number">4. </span>Generators</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/generators.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="generators">
<span id="id1"></span><h1><span class="section-number">4. </span>Generators<a class="headerlink" href="#generators" title="Link to this heading"></a></h1>
<p><cite>pysdg</cite> supports the following generators with their source links:</p>
<section id="replica-seq">
<h2><span class="section-number">4.1. </span>“replica/seq”<a class="headerlink" href="#replica-seq" title="Link to this heading"></a></h2>
<p><strong>Name:</strong> Sequential Decision Trees.</p>
<p><strong>Official Website:</strong> <a class="reference external" href="https://aetion.com/">Aetion</a> (previously <a class="reference external" href="https://news.aetion.com/aetion-acquires-synthetic-data-trailblazer-replica-analytics">Replica Analytics</a>)</p>
<p><strong>Reference Publication:</strong> <span id="id2">[<a class="reference internal" href="references.html#id12" title="K. El Emam, L. Mosquera, and C. Zheng. Optimizing the synthesis of clinical trial data using sequential trees. J Am Med Inform Assoc, Nov 2020. doi:10.1093/jamia/ocaa249.">1</a>]</span></p>
<p><strong>Licensing:</strong> Proprietary. A license shall be obtained from <a class="reference external" href="https://aetion.com/">Aetion</a> (formerly known as Replica).</p>
<p><strong>Overview:</strong> Similar to using a chaining method for multi-label classification problems, sequential decision trees (SEQ) generate synthetic data using conditional trees in a sequential fashion <span id="id4">[<a class="reference internal" href="references.html#id13" title="T. Hothorn, K. Hornik, and A. Zeileis. Unbiased recursive partitioning: a conditional inference framework. Journal of Computational and Graphical Statistics, 15(3):651-674, Sep 2006. doi:10.1198/106186006X133933.">2</a>]</span>, <span id="id5">[<a class="reference internal" href="references.html#id14" title="J. Read, B. Pfahringer, G. Holmes, and E. Frank. Classifier chains for multi-label classification. In W. Buntine, M. Grobelnik, D. Mladenić, and J. Shawe-Taylor, editors, Machine Learning and Knowledge Discovery in Databases, Lecture Notes in Computer Science, pages 254-269. Springer, Berlin, Heidelberg, 2009. doi:10.1007/978-3-642-04174-7_17.">3</a>]</span>. It has been commonly employed in the healthcare and social science domains for data synthesis <span id="id6">[<a class="reference internal" href="references.html#id23" title="D. S. Quintana. A synthetic dataset primer for the biobehavioural sciences to promote reproducibility and hypothesis generation. eLife, 9:e53275, 2020. doi:10.7554/eLife.53275.">4</a>]</span>.</p>
</section>
<section id="synthcity-bayesian-network">
<h2><span class="section-number">4.2. </span>“synthcity/bayesian_network”<a class="headerlink" href="#synthcity-bayesian-network" title="Link to this heading"></a></h2>
<p><strong>Name:</strong> Bayesian Network.</p>
<p><strong>Official Website:</strong> <a class="reference external" href="https://synthcity.readthedocs.io/en/latest/generated/synthcity.plugins.generic.plugin_bayesian_network.html">Bayesian Network</a></p>
<p><strong>Reference Publication:</strong> <span id="id7">[<a class="reference internal" href="references.html#id24" title="A. Ankan and A. Panda. Pgmpy: probabilistic graphical models using python. In Python in Science Conference, 6-11. Austin, Texas, 2015. doi:10.25080/Majora-7b98e3ed-001.">5</a>]</span></p>
<p><strong>Licensing:</strong> <a class="reference external" href="https://github.com/vanderschaarlab/synthcity/blob/main/LICENSE">Apache License 2.0 (BN)</a></p>
<p><strong>Overview:</strong> Bayesian Networks (BN) are models based on Directed Acyclic Graphs that consist of nodes representing the random variables and arcs representing the dependencies among these variables. To construct the BN model, the first step is to find the optimal network topology, and then to estimate the optimal parameters [14]. Starting with a random initial network structure, the Hill Climb heuristic search is used to find the optimal structure. Then, the conditional probability distributions are estimated using the maximum a posteriori estimator [15]. Once the network structure and the parameters are estimated, we can initialize the nodes with no incoming arcs by sampling from their marginal distributions and predict the rest of the connected variables using the estimated parameters. [16]</p>
</section>
<section id="synthcity-ctgan">
<h2><span class="section-number">4.3. </span>“synthcity/ctgan”<a class="headerlink" href="#synthcity-ctgan" title="Link to this heading"></a></h2>
<p><strong>Name:</strong> Conditional Tabular Generative Adversarial Network.</p>
<p><strong>Official Website:</strong> <a class="reference external" href="https://synthcity.readthedocs.io/en/latest/generated/synthcity.plugins.generic.plugin_ctgan.html">CTGAN</a></p>
<p><strong>Reference Publication:</strong> <span id="id8">[<a class="reference internal" href="references.html#id11" title="Lei Xu, Maria Skoularidou, Alfredo Cuesta-Infante, and Kalyan Veeramachaneni. Modeling tabular data using conditional gan. 2019. URL: https://arxiv.org/abs/1907.00503, arXiv:1907.00503.">6</a>]</span></p>
<p><strong>Licensing:</strong> <a class="reference external" href="https://github.com/vanderschaarlab/synthcity/blob/main/LICENSE">Apache License 2.0 (CTGAN)</a></p>
<p><strong>Overview:</strong> A basic generative adversarial network (GAN) consists of two artificial neural networks (ANNs), a generator and a discriminator [17]. The generator and the discriminator play a min-max game. The input to the generator is noise, while its output is synthetic data. The discriminator has two inputs: the real training data and the synthetic data generated by the generator. The output of the discriminator indicates whether its input is real or synthetic. The generator is trained to <em>trick</em> the discriminator by generating samples that look real. On the other hand, the discriminator is trained to maximize its discriminatory capability.
Among all the variations of GAN architectures, the conditional tabular GAN (CTGAN) is often used in tabular data synthesis [18]. CTGAN builds on conditional GANs by addressing the multimodal distributions of continuous variables and the highly imbalanced categorical variables [16]. CTGAN solves the first problem by proposing a per-mode normalization technique. For the second problem, each category of a categorical variable serves as the condition passed to the GAN.</p>
</section>
<section id="synthcity-tvae">
<h2><span class="section-number">4.4. </span>“synthcity/tvae”<a class="headerlink" href="#synthcity-tvae" title="Link to this heading"></a></h2>
<p><strong>Name:</strong> Tabular Variational Autoencoder.</p>
<p><strong>Official Website:</strong> <a class="reference external" href="https://synthcity.readthedocs.io/en/latest/generated/synthcity.plugins.generic.plugin_tvae.html">TVAE</a></p>
<p><strong>Reference Publication:</strong> <span id="id9">[<a class="reference internal" href="references.html#id11" title="Lei Xu, Maria Skoularidou, Alfredo Cuesta-Infante, and Kalyan Veeramachaneni. Modeling tabular data using conditional gan. 2019. URL: https://arxiv.org/abs/1907.00503, arXiv:1907.00503.">6</a>]</span></p>
<p><strong>Licensing:</strong> <a class="reference external" href="https://github.com/vanderschaarlab/synthcity/blob/main/LICENSE">Apache License 2.0 (TVAE)</a></p>
<p><strong>Overview:</strong> Variational autoencoders (VAE) use ANNs and involve two steps (encoding and decoding) to generate new samples [19]. First, an encoder is generated to compress input data into a lower-dimensional latent space, in which the data points are represented by distributions. The second step is a decoding process, in which new data samples are reconstructed as output from the latent space. The neural network is optimized by minimizing the reconstruction loss between the output and the input. In TVAE, the generator directly models the distribution of mixed-type tabular data, which includes both continuous and discrete variables. The model learns to represent continuous variables using Gaussian distributions, while categorical variables are handled using softmax outputs. This allows TVAE to generate realistic synthetic tabular data, preserving the statistical properties of the original dataset.</p>
</section>
<section id="synthcity-rtvae">
<h2><span class="section-number">4.5. </span>“synthcity/rtvae”<a class="headerlink" href="#synthcity-rtvae" title="Link to this heading"></a></h2>
<p><strong>Name:</strong> Robust Tabular Variational Autoencoder.</p>
<p><strong>Official Website:</strong> <a class="reference external" href="https://synthcity.readthedocs.io/en/latest/generated/synthcity.plugins.generic.plugin_rtvae.html">RTVAE</a></p>
<p><strong>Reference Publication:</strong> <span id="id10">[<a class="reference internal" href="references.html#id9" title="Haleh Akrami, Sergul Aydore, Richard M. Leahy, and Anand A. Joshi. Robust variational autoencoder for tabular data with beta divergence. 2020. URL: https://arxiv.org/abs/2006.08204, arXiv:2006.08204.">7</a>]</span></p>
<p><strong>Licensing:</strong> <a class="reference external" href="https://github.com/vanderschaarlab/synthcity/blob/main/LICENSE">Apache License 2.0 (RTVAE)</a></p>
<p><strong>Overview:</strong> is an extension of the standard TVAE designed to handle outliers in tabular data by incorporating β-divergence into the VAE framework. Unlike TVAE, which relies on traditional KL-divergence for reconstruction loss, RTVAE replaces this with β-divergence, making the model more resilient to anomalies and contaminated datasets. This modification reduces the sensitivity of the reconstruction loss to extreme values, which can otherwise disproportionately affect training. RTVAE outperforming standard TVAE when the data contains outliers.</p>
</section>
<section id="synthcity-arf">
<h2><span class="section-number">4.6. </span>“synthcity/arf”<a class="headerlink" href="#synthcity-arf" title="Link to this heading"></a></h2>
<p><strong>Name:</strong> Adversarial Random Forests.</p>
<p><strong>Official Website:</strong> <a class="reference external" href="https://synthcity.readthedocs.io/en/latest/generated/synthcity.plugins.generic.plugin_goggle.html">ARF</a></p>
<p><strong>Reference Publication:</strong> <span id="id11">[<a class="reference internal" href="references.html#id8" title="David S. Watson, Kristin Blesch, Jan Kapar, and Marvin N. Wright. Adversarial random forests for density estimation and generative modeling. 2023. URL: https://arxiv.org/abs/2205.09435, arXiv:2205.09435.">8</a>]</span></p>
<p><strong>Licensing:</strong> <a class="reference external" href="https://github.com/vanderschaarlab/synthcity/blob/main/LICENSE">Apache License 2.0 (ARF)</a></p>
<p><strong>Overview:</strong> Inspired by Generative Adversarial Networks (GANs), Adversarial Random Forests (ARFs) employ a recursive process where trees iteratively learn the structural properties of data by alternating between rounds of data generation and discrimination. This allows the model to gradually refine its understanding of the data distribution. Unlike classic tree-based models, ARFs provide smooth density estimations and can generate fully synthetic data, making them highly effective for tasks such as data augmentation and imputation.</p>
</section>
<section id="synthcity-nflow">
<h2><span class="section-number">4.7. </span>“synthcity/nflow”<a class="headerlink" href="#synthcity-nflow" title="Link to this heading"></a></h2>
<p><strong>Name:</strong> Neural Spline Flows.</p>
<p><strong>Official Website:</strong> <a class="reference external" href="https://synthcity.readthedocs.io/en/latest/generated/synthcity.plugins.generic.plugin_nflow.html">NFlow</a></p>
<p><strong>Reference Publication:</strong> <span id="id12">[<a class="reference internal" href="references.html#id10" title="Conor Durkan, Artur Bekasov, Iain Murray, and George Papamakarios. Neural spline flows. 2019. URL: https://arxiv.org/abs/1906.04032, arXiv:1906.04032.">9</a>]</span></p>
<p><strong>Licensing:</strong> <a class="reference external" href="https://github.com/vanderschaarlab/synthcity/blob/main/LICENSE">Apache License 2.0 (NFLOW)</a></p>
<p><strong>Overview:</strong> Neural Spline Flows (NFLOW) are a type of normalizing flow model designed to enhance the flexibility of transformations used in generative models and density estimation. NFLOW utilizes monotonic rational-quadratic splines to implement invertible transformations, offering a significant improvement over traditional affine or additive transformations typically used in flow-based models.
The key advantage of NFLOW lies in its ability to model complex, multi-modal distributions by allowing smooth, non-linear deformations of data while maintaining analytic invertibility. This is achieved by defining transformations using a series of spline segments, ensuring that the inverse and Jacobian determinant calculations remain efficient and exact. By incorporating spline-based transformations, NFLOW bridges the performance gap between autoregressive flows and coupling-based flows, resulting in improved density estimation and generative modeling performance for high-dimensional data, such as images and tabular datasets.</p>
</section>
<section id="yandex-tabddpm">
<h2><span class="section-number">4.8. </span>“yandex/tabddpm”<a class="headerlink" href="#yandex-tabddpm" title="Link to this heading"></a></h2>
<p><strong>Name:</strong> Tabular Denoising Diffusion Probabilistic Model.</p>
<p><strong>Official Website:</strong> <a class="reference external" href="https://github.com/yandex-research/tab-ddpm">TabDDPM</a></p>
<p><strong>Reference Publication:</strong> <span id="id13">[<a class="reference internal" href="references.html#id7" title="Akim Kotelnikov, Dmitry Baranchuk, Ivan Rubachev, and Artem Babenko. TabDDPM: modelling tabular data with diffusion models. In Proceedings of the 40th International Conference on Machine Learning, 17564–17579. PMLR, 2023. ISSN: 2640-3498. URL: https://proceedings.mlr.press/v202/kotelnikov23a.html (visited on 2025-03-11).">10</a>]</span></p>
<p><strong>Licensing:</strong> <a class="reference external" href="https://github.com/yandex-research/tab-ddpm/blob/main/LICENSE.md">MIT License (TABDDPM)</a></p>
<p><strong>Overview:</strong> Tabular Denoising Diffusion Probabilistic Model (TabDDPM)  is a generative model designed to produce high-quality synthetic tabular data by leveraging diffusion models, which iteratively corrupt and denoise data to approximate complex distributions through a Markov chain process. The forward Markov process gradually adds noise to the data, transforming it into a Gaussian or categorical noise distribution, while the reverse Markov process, learned by a neural network, progressively denoises the data to reconstruct the original distribution. Unlike traditional GANs or VAEs, TabDDPM handles heterogeneous tabular datasets with mixed numerical and categorical features by applying Gaussian diffusion to continuous variables and multinomial diffusion to categorical ones. This flexibility allows TabDDPM to outperform other generative models in capturing feature correlations and preserving data privacy. Its ability to generate realistic synthetic data makes it useful for data augmentation, imbalanced datasets, and privacy-preserving applications.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <cite>yandex/tabddpm</cite> model requires a GPU to perform properly. Ensure that your environment has access to a compatible GPU to achieve optimal performance.</p>
</div>
</section>
<section id="amazon-tabsyn">
<h2><span class="section-number">4.9. </span>“amazon/tabsyn”<a class="headerlink" href="#amazon-tabsyn" title="Link to this heading"></a></h2>
<p><strong>Name:</strong> Mixed-Type Tabular Data Model (comprises transformer-based VAE and diffusion models) .</p>
<p><strong>Official Website:</strong> <a class="reference external" href="https://github.com/amazon-science/tabsyn">TabSyn</a></p>
<p><strong>Reference Publication:</strong> <span id="id14">[<a class="reference internal" href="references.html#id3" title="Hengrui Zhang, Jiani Zhang, Balasubramaniam Srinivasan, Zhengyuan Shen, Xiao Qin, Christos Faloutsos, Huzefa Rangwala, and George Karypis. Mixed-type tabular data synthesis with score-based diffusion in latent space. arXiv preprint arXiv:2310.09656, 2023.">11</a>]</span></p>
<p><strong>Licensing:</strong> <a class="reference external" href="https://github.com/amazon-science/tabsyn/blob/main/LICENSE">Apache License 2.0 (TABSYN)</a></p>
<p><strong>Overview:</strong> TabSyn is a generative model for synthesizing tabular data by combining a Variational Autoencoder (VAE) with score-based diffusion models in the latent space. Unlike TabDDPM, which applies diffusion directly to raw tabular data, TabSyn first encodes the data into a continuous latent space using a transformer-based VAE, enabling it to handle mixed numerical and categorical features more effectively. This approach simplifies the diffusion process, reduces the need for separate handling of data types, and improves generation quality. TabSyn also employs a linear noise schedule, allowing it to generate high-fidelity data with fewer reverse steps (under 20), making it faster and more efficient than TabDDPM, which typically requires more steps for similar performance. By operating in the latent space, TabSyn outperforms TabDDPM in capturing complex column dependencies and producing more accurate synthetic data.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <cite>amazon/tabsyn</cite> model requires a GPU to perform properly. Ensure that your environment has access to a compatible GPU to achieve optimal performance.</p>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="usage.html" class="btn btn-neutral float-left" title="3. Usage" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="references.html" class="btn btn-neutral float-right" title="5. References" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>