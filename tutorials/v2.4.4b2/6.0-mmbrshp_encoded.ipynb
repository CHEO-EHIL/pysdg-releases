{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Warning : Cuda libraries were not detected on the system or could not be loaded ; using cpu only mode\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pysdg.synth.generate import Generator  \n",
    "from pysdg.privacy.mmbrshp import calc_mmbrshp_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the population csv file\n",
    "raw_data = pd.read_csv('raw_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the population into training and holdout datasets and save them to csv files. Use your desired split ratio.\n",
    "raw_train = raw_data.sample(frac=0.5, random_state=1)\n",
    "raw_holdout = raw_data.drop(raw_train.index)\n",
    "\n",
    "raw_train.to_csv('raw_train.csv', index=False)\n",
    "raw_holdout.to_csv('raw_holdout.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-04 19:05:26,227 - pysdg - INFO - 1222045 - generate.py:88 - **************Started logging the generator: synthcity_bayesian_network, num_cores= None.**************\n",
      "2025-02-04 19:05:26,269 - pysdg - INFO - 1222045 - generate.py:209 - Checking the input metadata for any conflict in variable indexes - Passed.\n",
      "2025-02-04 19:05:27,335 - pysdg - INFO - 1222045 - generate.py:277 - The dataset ['tutorial_data'] is loaded into the generator synthcity_bayesian_network\n",
      "[2025-02-04T19:05:29.154864-0500][1222045][CRITICAL] module disabled: /share/personal/skababji/conda_envs/pysdg_dev/lib/python3.10/site-packages/synthcity/plugins/generic/plugin_goggle.py\n",
      "2025-02-04 19:05:35,061 - pysdg - INFO - 1222045 - generate.py:662 - Started training using synthcity_bayesian_network...\n",
      "INFO:pysdg:Started training using synthcity_bayesian_network...\n",
      "2025-02-04 19:06:33,132 - pysdg - INFO - 1222045 - generate.py:667 - Completed training using synthcity_bayesian_network.\n",
      "INFO:pysdg:Completed training using synthcity_bayesian_network.\n",
      "2025-02-04 19:06:34,167 - pysdg - INFO - 1222045 - generate.py:715 - Generating synth no. 0 of size (5000, 12) -- Completed!\n",
      "INFO:pysdg:Generating synth no. 0 of size (5000, 12) -- Completed!\n"
     ]
    }
   ],
   "source": [
    "# Use the training dataset to train your model.\n",
    "gen1=Generator(\"synthcity_bayesian_network\")\n",
    "gen1.load('raw_train.csv', 'raw_info.json')\n",
    "gen1.train()\n",
    "\n",
    "# Extract the ENCODED version for the real  dataset. Only the ENCODED versions should be used to calculate the membership risk, otherwise an error will be raised.\n",
    "enc_real_train=gen1.enc_real\n",
    "\n",
    "# Generate the required number of data points and synthetic version. In this example, we generate one synthetic dataset version with the same number of rows as the real dataset.\n",
    "gen1.gen(num_rows=len(enc_real_train), num_synths=1)\n",
    "\n",
    "# Extract the ENCODED version for the synthetic dataset.\n",
    "enc_synth=gen1.enc_synths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-04 19:06:34,256 - pysdg - INFO - 1222045 - generate.py:88 - **************Started logging the generator: dummy, num_cores= None.**************\n",
      "INFO:pysdg:**************Started logging the generator: dummy, num_cores= None.**************\n",
      "2025-02-04 19:06:34,276 - pysdg - INFO - 1222045 - generate.py:209 - Checking the input metadata for any conflict in variable indexes - Passed.\n",
      "INFO:pysdg:Checking the input metadata for any conflict in variable indexes - Passed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-04 19:06:35,403 - pysdg - INFO - 1222045 - generate.py:277 - The dataset ['tutorial_data'] is loaded into the generator dummy\n",
      "INFO:pysdg:The dataset ['tutorial_data'] is loaded into the generator dummy\n"
     ]
    }
   ],
   "source": [
    "# Create a 'dummy' generator to obtain the ENCODED version of the holdout dataset.\n",
    "gen2=Generator()\n",
    "gen2.load('raw_holdout.csv', 'raw_info.json')\n",
    "enc_real_holdout=gen2.enc_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the unnecessary columns from all ENCODED datasets. All columns that include '_missing' in their names should be removed. These columns are added by pysdg for tracking purposes and are not part of the original dataset.\n",
    "enc_real_train = enc_real_train.loc[:, ~enc_real_train.columns.str.contains('_missing')]\n",
    "enc_synth = enc_synth.loc[:, ~enc_synth.columns.str.contains('_missing')]\n",
    "enc_real_holdout = enc_real_holdout.loc[:, ~enc_real_holdout.columns.str.contains('_missing')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the ENCODED information about the datasets to extract the population size.\n",
    "population_size=gen1.enc_real_info['population_size'][0]\n",
    "\n",
    "# Define your desired size of the attack dataset. In this example, we use 20% of the training dataset.\n",
    "attack_data_size=int(0.2*len(enc_real_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating membership disclosure risk\n",
      "Relative F1 score = 0.0099601593625498\n",
      "Naive F1 score = 0.010272899577270183\n"
     ]
    }
   ],
   "source": [
    "# Calculate the membership risk with default settings of quasi-identifiers (all variable names will be considered by default).\n",
    "res=calc_mmbrshp_risk(enc_synth, enc_real_train, enc_real_holdout, population_size=population_size, attack_size=attack_data_size)\n",
    "print(f\"Relative F1 score = {res['f1']}\")\n",
    "print(f\"Naive F1 score = {res['f_naive']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating membership disclosure risk\n",
      "Relative F1 score = 0.009950248756218907\n",
      "Naive F1 score = 0.010272899577270183\n"
     ]
    }
   ],
   "source": [
    "# Calculate the membership risk when all variable names are explicitly passed as quasi-identifiers.\n",
    "quasi_identifiers=enc_real_train.columns\n",
    "\n",
    "res=calc_mmbrshp_risk(enc_synth, enc_real_train, enc_real_holdout, population_size=population_size, attack_size=attack_data_size, quasi_vars=quasi_identifiers)\n",
    "print(f\"Relative F1 score = {res['f1']}\")\n",
    "print(f\"Naive F1 score = {res['f_naive']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating membership disclosure risk\n",
      "Relative F1 score = 0.009950248756218907\n",
      "Naive F1 score = 0.010272899577270183\n"
     ]
    }
   ],
   "source": [
    "# Calculate the membership risk when selected variables are used as quasi-identifiers. In this example, we use the ENCODED variable names corresponding to the indexes that were initially defined in the input json file. \n",
    "quasi_identifiers = gen1.enc_real_info['quasi_names']\n",
    "\n",
    "res=calc_mmbrshp_risk(enc_synth, enc_real_train, enc_real_holdout, population_size=population_size, attack_size=attack_data_size, quasi_vars=quasi_identifiers)\n",
    "print(f\"Relative F1 score = {res['f1']}\")\n",
    "print(f\"Naive F1 score = {res['f_naive']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pysdg_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
