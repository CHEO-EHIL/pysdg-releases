---
title: "pysdg in R"
output: html_document
---

# Tutorial: Quick Start

**This tutorial demonstrates the core functions of pysdg.** It assumes that pysdg is already installed in a conda environment. The package reticulate is used to interface with Python. For respective installation instructions, please consult the pysdg documentation. 

**Core Functions** in pysdg include loading (real) training data, training a generator, generating synthetic data and unloading.

## Step 1: Activate the Conda Environment
For the purpose of this tutorial, we assume that your conda environment was named `pysd_dev`, so the first step is to activate it. Note that Step 1 is *not* required if you are working with a pre-defined Docker image that has the required environment including its dependencies pre-installed.

```{r}
library(reticulate) 
use_condaenv("pysdg_dev", required = TRUE) 
```

## Step 2: Import Core Functions
Relevant functions are imported from pysdg: 
* synth.load for standardized loading of datasets via pysdg, 
* synth.generate to generate a synthetic dataset and 

```{r}
synth.generate <- reticulate::import("pysdg.synth.generate") 
synth.load <- reticulate::import("pysdg.synth.load")
```

## Step 3: Define the Paths 
To generate synthetic data, we specify the path to the (real) training dataset that must be stored as csv file. 
```{r}
current_file_path <- rstudioapi::getActiveDocumentContext()$path
train_data_path <- paste0(dirname(current_file_path), "/raw_data.csv")
```

## Step 4: Create a Generator Object
You can choose between different generators. We use Bayesian Network as example. Check out the most recent documentation: we extend the selection of generators regularly. 

```{r}
gen <- synth.generate$Generator("synthcity_bayesian_network")
```

## Step 5: Load (Real) Training Data With Provided Metadata
A json file is defined with metadata with respect to datatypes. Exemplar dataset and corresponding json file are provided in this folder. Load the (real) training dataset and json file into the created object (Step 4). This loading process converts the datatypes in the dataset according to the specifications in the json file.

```{r}
raw_info_path <- paste0(dirname(current_file_path), "/raw_info.json")
train_data <- gen$load(train_data_path, raw_info_path) 
head(train_data,10)
```
### Alternative: Load (Real) Training Data Without Metadata
Load the (real) training dataset into the created object (Step 4). Datatypes are inferred. As datatype handling in the generation process differs, this alternative loading process can have a negative impact on the generation process. 

```{r}
train_data <- gen$load(train_data_path) 
head(train_data,10)
```

## Step 6: Train the Generator
The generator is trained on the loaded (real) training dataset. 

```{r}
gen$train() 
```

## Step 7: Generate Synthetic Data
The desired number of synthetic datasets (num_synths) can be generated. Typically, 10 synthetic datasets are generated to account for the stochasticity of the process. The number of rows (num_rows) typically match the number of rows in the real data.

```{r}
gen$gen(num_rows=nrow(train_data), num_synths = 10) 
```

## Step 8: Retrieve the Synthetic Datasets
The generated data is stored within the generator object. We can extract (i.e., unload) them as a list and can index each dataset individually. 

```{r}
synths <- gen$unload()
synth <- synths[[1]]
head(synth, 10)
```
